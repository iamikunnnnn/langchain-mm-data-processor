import base64
import io
import os
import time
import tempfile
import requests
import streamlit as st
import json
import uuid

from PIL import Image

from chatbot_cv import Cv_Chatbot
from machine_learning_model import *

temp_file_path_list = []  # ä¿å­˜ä¸´æ—¶æ–‡ä»¶çš„åå­—ç”¨äºåç»­åˆ é™¤ï¼ˆæ³¨ï¼šåˆ é™¤åŠŸèƒ½æš‚æœªå®Œæˆï¼‰

st.set_page_config(page_title="AI æ•°æ®åˆ†æ", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– AI æ•°æ®åˆ†æ")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "sessions" not in st.session_state:
    # å­˜å‚¨æ‰€æœ‰ä¼šè¯ï¼Œæ ¼å¼ï¼š{session_id: {"name": str, "history": list, "thread_id": str}}
    default_session_id = str(uuid.uuid4())
    st.session_state.sessions = {
        default_session_id: {
            "name": "ä¼šè¯ 1",
            "history": [],
            "thread_id": str(uuid.uuid4())
        }
    }
    st.session_state.current_session_id = default_session_id

if "is_voice_mode" not in st.session_state:
    st.session_state.is_voice_mode = False

# åç«¯æ¥å£é…ç½®
FASTAPI_URL = "http://127.0.0.1:8000"
CHAT_ENDPOINT = f"{FASTAPI_URL}/chat"
RAG_ENDPOINT = f"{FASTAPI_URL}/chat/rag"
VISUALIZATION_ENDPOINT = f"{FASTAPI_URL}/chat/visualization"

cv_chatbot = Cv_Chatbot()


# è·å–å½“å‰ä¼šè¯
def get_current_session():
    return st.session_state.sessions[st.session_state.current_session_id]


def get_current_thread_id():
    return get_current_session()["thread_id"]


# ä¾§è¾¹æ ï¼šä¼šè¯ç®¡ç†
with st.sidebar:
    st.header("ğŸ“‹ ä¼šè¯ç®¡ç†")

    # ä¼šè¯é€‰æ‹©å™¨
    session_names = {sid: sdata["name"] for sid, sdata in st.session_state.sessions.items()}
    selected_session_name = st.selectbox(
        "é€‰æ‹©ä¼šè¯",
        options=list(session_names.values()),
        index=list(session_names.keys()).index(st.session_state.current_session_id)
    )

    # æ›´æ–°å½“å‰ä¼šè¯ID
    for sid, name in session_names.items():
        if name == selected_session_name:
            st.session_state.current_session_id = sid
            break

    col1, col2 = st.columns(2)
    with col1:
        if st.button("â• æ–°å»ºä¼šè¯", use_container_width=True):
            new_session_id = str(uuid.uuid4())
            session_count = len(st.session_state.sessions) + 1
            st.session_state.sessions[new_session_id] = {
                "name": f"ä¼šè¯ {session_count}",
                "history": [],
                "thread_id": str(uuid.uuid4())
            }
            st.session_state.current_session_id = new_session_id
            st.rerun()

    with col2:
        if st.button("ğŸ—‘ï¸ åˆ é™¤ä¼šè¯", use_container_width=True):
            if len(st.session_state.sessions) > 1:
                del st.session_state.sessions[st.session_state.current_session_id]
                st.session_state.current_session_id = list(st.session_state.sessions.keys())[0]
                st.rerun()
            else:
                st.warning("è‡³å°‘ä¿ç•™ä¸€ä¸ªä¼šè¯")

    # é‡å‘½åä¼šè¯
    new_name = st.text_input("é‡å‘½åå½“å‰ä¼šè¯", value=get_current_session()["name"])
    if new_name != get_current_session()["name"]:
        get_current_session()["name"] = new_name
        st.rerun()

    st.divider()

    # æ˜¾ç¤ºå½“å‰ä¼šè¯çš„thread_idï¼ˆè°ƒè¯•ç”¨ï¼‰
    with st.expander("ğŸ” ä¼šè¯ä¿¡æ¯"):
        st.text(f"Thread ID: {get_current_thread_id()[:8]}...")
        st.text(f"æ¶ˆæ¯æ•°: {len(get_current_session()['history'])}")

    st.divider()

    # æ–‡ä»¶ä¸Šä¼ 
    st.header("ğŸ“ æ–‡ä»¶å¤„ç†")
    uploaded_files = st.file_uploader(
        "é€‰æ‹©è¦ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰",
        type=None,
        accept_multiple_files=True
    )

    file_path_list = []
    if uploaded_files is not None:
        if st.button("å¤„ç†æ–‡ä»¶å¹¶ä¸Šä¼ çŸ¥è¯†åº“"):
            for file in uploaded_files:
                st.write(f"âœ… å·²ä¸Šä¼ : {file.name}")
                ext = os.path.splitext(file.name)[1]
                with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as f:
                    f.write(file.getvalue())
                    f.flush()
                    temp_file_path = f.name
                    temp_file_path_list.append(temp_file_path)
                    file_path_list.append(temp_file_path)

            if not st.session_state.is_voice_mode:
                response = requests.post(
                    RAG_ENDPOINT,
                    json={
                        "file_path_list": file_path_list,
                        "thread_id": get_current_thread_id()
                    },
                    params={"mode": "nlp"}
                )

    if st.button("ğŸ“Š å¯è§†åŒ–"):
        response = requests.post(
            VISUALIZATION_ENDPOINT,
            json={"thread_id": get_current_thread_id()}
        )
        if response.json().get("success"):
            fig_dict = response.json().get("response")

            binary_fig_b64 = fig_dict["binary_fig"]
            fit_true_fig_b64 = fig_dict["fit_true_fig"]
            predict_true_b64 = fig_dict["predict_true_fig"]

            binary_fig_bytes = base64.b64decode(binary_fig_b64)
            fit_true_fig_bytes = base64.b64decode(fit_true_fig_b64)
            predict_true_bytes = base64.b64decode(predict_true_b64)

            binary_fig_img = Image.open(io.BytesIO(binary_fig_bytes))
            fit_true_fig_img = Image.open(io.BytesIO(fit_true_fig_bytes))
            predict_true_img = Image.open(io.BytesIO(predict_true_bytes))

            get_current_session()["history"].append({"role": "assistant", "content": binary_fig_img, "type": "image"})
            get_current_session()["history"].append({"role": "assistant", "content": fit_true_fig_img, "type": "image"})
            get_current_session()["history"].append({"role": "assistant", "content": predict_true_img, "type": "image"})

            st.rerun()

# æ˜¾ç¤ºå½“å‰ä¼šè¯çš„å¯¹è¯å†å²
for msg in get_current_session()["history"]:
    with st.chat_message(msg["role"]):
        if msg["type"] == "text":
            st.markdown(msg["content"])
        elif msg["type"] == "image":
            if isinstance(msg["content"], str):
                st.text(msg["content"])
            else:
                msg["content"].seek(0)
                st.image(msg["content"])

# æ ¸å¿ƒé€»è¾‘ï¼šæ ¹æ®æ¨¡å¼å¤„ç†å¯¹è¯
if input_msg := st.chat_input("æ¥å’Œæˆ‘èŠå¤©å§~~~", accept_file="multiple",
                              file_type=['png', 'jpg', 'jpeg', "xlsx", "csv"]):
    if input_msg.text:
        if not st.session_state.is_voice_mode:
            try:
                response = requests.post(
                    CHAT_ENDPOINT,
                    json={
                        "prompt": input_msg.text,
                        "thread_id": get_current_thread_id()
                    },
                    params={"mode": "nlp"}
                )
                print(response.json())
                response.raise_for_status()

                get_current_session()["history"].append({"role": "human", "content": input_msg.text, "type": "text"})
                get_current_session()["history"].append({"role": "assistant", "content": response.text, "type": "text"})

                st.rerun()

            except ValueError as e:
                st.error(f"æ–‡æœ¬å¯¹è¯å¤±è´¥ï¼š{str(e)}")

    if input_msg.files:
        st.warning("æ–‡ä»¶è¯»å–ä¸­")

        for file in input_msg.files:
            file_name = file.name.lower()
            file_type = None

            if file_name.endswith(('.png', '.jpg', '.jpeg')):
                file_type = "image"
                st.warning(f"æ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶ï¼š{file_name}")
            elif file_name.endswith(('.xlsx', '.csv', '.json')):
                file_type = "tabel"
                st.warning(f"æ£€æµ‹åˆ°è¡¨æ ¼æ–‡ä»¶ï¼š{file_name}")
            else:
                st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š{file_name}")
                continue

            if file_type == "image":
                with st.chat_message("human"):
                    st.image(file, width=100)
                    get_current_session()["history"].append({"role": "human", "content": file, "type": "image"})
                    get_current_session()["history"].append(
                        {"role": "human", "content": input_msg.text, "type": "text"})

                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as f:
                        f.write(file.getvalue())
                        f.flush()
                        temp_file_path = f.name

                        base64_str = cv_chatbot.img2base64(temp_file_path)
                        prompt = cv_chatbot.get_prompt(base64_str)
                        print(prompt)

                    if not st.session_state.is_voice_mode:
                        response = requests.post(
                            CHAT_ENDPOINT,
                            json={
                                "prompt": prompt,
                                "thread_id": get_current_thread_id()
                            },
                            params={"mode": "cv"}
                        )

                        get_current_session()["history"].append(
                            {"role": "assistant", "content": response.json(), "type": "text"})
                        st.rerun()
                except Exception as e:
                    st.error(e)

            if file_type == "tabel":
                try:
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".csv") as f:
                        f.write(file.getvalue())
                        f.flush()
                        temp_file_path = f.name
                        prompt = temp_file_path
                        temp_file_path_list.append(temp_file_path)
                        get_current_session()["history"].append(
                            {"role": "human", "content": temp_file_path, "type": "text"})

                    if not st.session_state.is_voice_mode:
                        response = requests.post(
                            CHAT_ENDPOINT,
                            json={
                                "prompt": prompt,
                                "thread_id": get_current_thread_id()
                            },
                            params={"mode": "nlp"}
                        )
                        get_current_session()["history"].append(
                            {"role": "assistant", "content": response.json(), "type": "text"})
                        st.rerun()
                except Exception as e:
                    print(e)

# è¯­éŸ³æ¨¡å¼
try:
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ¤ å¯åŠ¨è¯­éŸ³ç›‘å¬"):
            st.session_state.is_voice_mode = True
            response = requests.post(
                CHAT_ENDPOINT,
                json={
                    "prompt": "å¼€å§‹è¯­éŸ³ç›‘å¬",
                    "thread_id": get_current_thread_id()
                },
                params={"mode": "voice"}
            )
            print(response.json())
            response.raise_for_status()
            st.chat_message("human").info("å·²å¯åŠ¨è¯­éŸ³æ¨¡å¼ï¼Œè¯·è¯´å‡ºå”¤é†’è¯...")

    with col2:
        if st.button("ğŸ”‡ å…³é—­è¯­éŸ³ç›‘å¬"):
            st.session_state.is_voice_mode = False
            response = requests.post(
                CHAT_ENDPOINT,
                json={
                    "prompt": "å…³é—­è¯­éŸ³ç›‘å¬",
                    "thread_id": get_current_thread_id()
                },
                params={"mode": "voice"}
            )
            print(response.json())
            response.raise_for_status()
            st.chat_message("human").info("å·²å…³é—­è¯­éŸ³æ¨¡å¼")

except ValueError as e:
    st.error(f"è¯­éŸ³æ¨¡å¼æ“ä½œå¤±è´¥ï¼š{str(e)}")
finally:
    st.session_state.is_voice_mode = False